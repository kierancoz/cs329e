{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C S 329E HW7\n",
    "\n",
    "# Ensemble Methods and Skewed Data\n",
    "\n",
    "### Kieran Cosgrove & Alec Biggerstaff\n",
    "\n",
    "For this week's homework we are going explore two ensemble methods:\n",
    "\n",
    "  - AdaBoost, and\n",
    "  - Random Forests\n",
    "  \n",
    "Along with applying different KPIs (key performance indicators) that are more appropriate to highly skewed data sets. \n",
    "\n",
    "The dataset contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 237 frauds out of 142,167 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.17% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a [PCA transformation](https://en.wikipedia.org/wiki/Principal_component_analysis). Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount in Euros. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "At the end of this homework, I expect you to understand how to train and use ensemble classifiers, how to characterize model performance with ROC curves, and be familiar with the difference between accuracy, true positive rate, and positive predictive value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries you will use for this assignment, you may not import anything else\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# This is the credit card data provided, we'll use sklearn methods to do cross validation\n",
    "# to estimate error\n",
    "df_cc = pd.read_csv('cc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Partition the data for cross validation\n",
    "\n",
    "Load the data, and split the data set into $X$ (the feature dataframe, `df_X`) and $y$ (the target series `s_y`). Define our partitions.  \n",
    "\n",
    "We know this is a _super_ skewed data set, so we worry about our target class being underrepresented in a random k-fold selection. With this in mind, we use a [stratifed k-fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html), since it will preserve our class balance in our experiements. Use $k=3$, . Instantiate an instance of the `StratifiedKFold` class, and use the generator `split` to populate the test and train dictonaries:\n",
    "   - `d_train_df_X` : key is the fold number, value is the attribute training dataframe at that fold\n",
    "   - `d_test_df_X`  : key is the fold number, value is the attribute test dataframe at that fold\n",
    "   - `d_train_s_y`  : key is the fold number, value is the target training series at that fold\n",
    "   - `d_train_s_y`  : key is the fold number, value is the target test series at that fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_cc.drop(columns=['Class'])\n",
    "s_y = df_cc['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3,shuffle=True,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_df_X = dict()\n",
    "d_test_df_X = dict()\n",
    "d_train_s_y = dict()\n",
    "d_test_s_y = dict()\n",
    "\n",
    "# Your code here\n",
    "for indx, [train_index, test_index] in enumerate(skf.split(df_X, s_y)):\n",
    "    d_train_df_X[indx] = df_X.iloc[train_index]\n",
    "    d_test_df_X[indx] = df_X.iloc[test_index]\n",
    "    d_train_s_y[indx] = s_y.iloc[train_index]\n",
    "    d_test_s_y[indx] = s_y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the test data and verify that the target training is equally distributed as possible\n",
    "for key in d_test_s_y.keys():\n",
    "    print(d_test_s_y[key].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Test the Performance of AdaBoost\n",
    "\n",
    "When we talked about AdaBoost in class, we used a collection of \"Decision Stumps\". In this assignment, we will use the implementation of [AdaBoost in Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html).  As you browse the documentation, you will notice that the default base esimator in this implentation is a `DecisionTreeClassifier(max_depth=1)` (our friend the decision stump). \n",
    "\n",
    "After you fit an AdaBoost model, you can call the method `predict` to get a class prediction, or you can call `predict_proba` to get the probability of being in the class `0` or the class `1`. These probabilities are used when creating ROC curves. \n",
    "\n",
    "Loop over the $k$ folds using the dictionaries from the first problem, and for each fold calculate the accuracy, TPR, the PPV, and the FPR.  Plot the ROC curve for each fold. You may use the [plot roc curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html) from Scikit-learn.  There is a great example in the documentation [on plotting ROC curves in cross validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html) that is helpful.  \n",
    "\n",
    "When creating your AdaBoost classifier, please use the following parameters: \n",
    "`AdaBoostClassifier(n_estimators=25, random_state=23)`\n",
    "\n",
    "Save the predictions from the 3rd fold into a variable called `y_hat_ab` for use in a future problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "acc_ab = np.zeros(k)\n",
    "tpr_ab = np.zeros(k)\n",
    "ppv_ab = np.zeros(k)\n",
    "fpr_ab = np.zeros(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min, mean, and max TPR are: 0.00, 0.00, and 0.00\n",
      "The min, mean, and max PPV are: 0.00, 0.00, and 0.00\n",
      "The min, mean, and max ACC are: 0.00, 0.00, and 0.00\n"
     ]
    }
   ],
   "source": [
    "print('The min, mean, and max TPR are: {:.2f}, {:.2f}, and {:.2f}'.format(tpr_ab.min(), tpr_ab.mean(), tpr_ab.max()))\n",
    "print('The min, mean, and max PPV are: {:.2f}, {:.2f}, and {:.2f}'.format(ppv_ab.min(), ppv_ab.mean(), ppv_ab.max()))\n",
    "print('The min, mean, and max ACC are: {:.2f}, {:.2f}, and {:.2f}'.format(acc_ab.min(), acc_ab.mean(), acc_ab.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Test the Performance of Random Forests\n",
    "\n",
    "Now, let's try another ensemble method: Random Forests, again using the [Scikit-learn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). \n",
    "\n",
    "Following our book, we will build complete trees, with no pruning.  That means every leaf in the tree will be completelely pure, and if you exam an individual Decision Tree it would be overtrained to our training set.  While building the decision trees, at every internal node, we select $p$ attributes at random, and then find the best split that minimizes impurtity.  The value, $p$, is a hyperparamter of the Random Forest and corresponds to the `max_features` parameter in the Random Forest Class. \n",
    "\n",
    "After you fit an RandomForest model, you can call the method `predict` to get a class prediction, or you can call `predict_proba` to get the probability of being in the class `0` or the class `1`. These probabilities are used when creating ROC curves. \n",
    "\n",
    "Loop over the $k$ folds using the dictionaries from the first problem, and for each fold calculate the accuracy, TPR, the PPV, and the FPR.  Plot the ROC curve for each fold. You may use the [plot roc curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html) from Scikit-learn. There is a great example in the documentation [on plotting ROC curves in cross validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html) that is helpful.  \n",
    "\n",
    "When creating your Random Forest classifier, please use the following parameters: \n",
    "`RandomForestClassifier(criterion=\"entropy\", max_features=\"sqrt\", random_state=23)`\n",
    "\n",
    "Save the predictions from the 3rd fold into a variable called `y_hat_rf` for use in a future problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "acc_rf = np.zeros(k)\n",
    "tpr_rf = np.zeros(k)\n",
    "ppv_rf = np.zeros(k)\n",
    "fpr_rf = np.zeros(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min, mean, and max TPR are: 0.00, 0.00, and 0.00\n",
      "The min, mean, and max PPV are: 0.00, 0.00, and 0.00\n",
      "The min, mean, and max ACC are: 0.00, 0.00, and 0.00\n"
     ]
    }
   ],
   "source": [
    "print('The min, mean, and max TPR are: {:.2f}, {:.2f}, and {:.2f}'.format(tpr_rf.min(), tpr_rf.mean(), tpr_rf.max()))\n",
    "print('The min, mean, and max PPV are: {:.2f}, {:.2f}, and {:.2f}'.format(ppv_rf.min(), ppv_rf.mean(), ppv_rf.max()))\n",
    "print('The min, mean, and max ACC are: {:.2f}, {:.2f}, and {:.2f}'.format(acc_rf.min(), acc_rf.mean(), acc_rf.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 Calculate the Cost of Fraud \n",
    "\n",
    "In the above problems, we saved the predictions of the 3rd fold into the variables `y_hat_ab` and `y_hat_rf` for the AdaBoost and RandomForest models respectively. \n",
    "\n",
    "Now, Mr. Bank Man wants you to tell him how much money he is going to save if he deploys either of these fraud algorithms to the real-time payment processing system.  Assume that there is not a currently deployed fraud detection algorithm.  \n",
    "\n",
    "For every fraudulent transaction that is not predicted as fraudulent the bank looses twice that much money.  So, a fradulent charge for â‚¬10 is undectected, it costs the bank â‚¬20.  Also, if a charge is predicted as fradulent, but wasn't, it costs the bank a flat fee of â‚¬3 in customer service support to communicate with the customer, and mark the possible fraud as a normal transaction. \n",
    "\n",
    "Using the 3rd fold test sample, calculate how much money Mr Bank Man will save with each algorithm, and make a recommendation of which algorithm to deploy to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mr Bank man will save more money, if we deploy the <> algorithm! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
