{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C S 329E HW 3\n",
    "\n",
    "## Feature engineering and linear regression\n",
    "\n",
    "## Kieran Cosgrove\n",
    "\n",
    "For this weeks homework we are going to load in a data set that isn't the \"cleanest\", repair it, do some analysis on the features, estimate a continuous paramter using linear regression, and experiment with trying a few different methods of feature selection.  Is linear regression _really_ machine learning? Depends on who you ask, but it is definitely an important tool for data mining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import radians, sin, cos, sqrt\n",
    "import copy\n",
    "\n",
    "## Load in the melb_data_sold_train.csv file here\n",
    "df = pd.read_csv(\"melb_data_sold_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Fix the dataframe to remove any blanks\n",
    "The linear regression needs all values to be defined.  Use list-wise deletion to remove entries with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df\n",
    "for column_title in new_df:\n",
    "    new_df = new_df[new_df[column_title].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Add a new feature\n",
    "Toorak is known as one of the pricest suburbs in Melbourne.  Create a new column in your dataframe that is the distance in kilometers from the center of Toorak to the latitude/longitude of that row.  Use the latitude / longitude of (-37.841820, 145.015986) for the center of Toorak.  You may assume the Earth is spherical and has radius of 6371.0088km (the first property in the data frame (-37.68178,144.73779) is approx 30 km away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Define the Haversine distance as a function\n",
    "def haversine_distance(pt1, pt2):\n",
    "    #code here, make sure pt1 and pt2 are passed in as degrees (lat,long) and convert to radians before calculation\n",
    "    in_lat, in_long = radians(pt1[0]), radians(pt1[1])\n",
    "    other_lat, other_long = radians(pt2[0]), radians(pt2[1])\n",
    "    r = 6371.0088\n",
    "    \n",
    "    lat_delta = in_lat - other_lat\n",
    "    long_delta = in_long - other_long\n",
    "    #print(lat_delta, long_delta)\n",
    "    \n",
    "    return 2*r*np.arcsin(sqrt( (sin(lat_delta/2))**2 + cos(in_lat)*cos(other_lat)*(sin(long_delta/2)**2 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        4.261612\n",
       "3        4.621843\n",
       "4        4.374206\n",
       "6        4.780655\n",
       "7        4.152012\n",
       "          ...    \n",
       "7985    16.998846\n",
       "7988    18.491623\n",
       "7995    11.798784\n",
       "7997    11.986684\n",
       "7999    29.708163\n",
       "Name: distance_to_toorak, Length: 3910, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2 : Use the defintion to calculate the distance for every row in the data frame\n",
    "# Carry on the new data frame with the extra column named 'distance_to_toorak' for the rest of the homework\n",
    "toorak = (-37.841820, 145.015986)\n",
    "new_df[\"distance_to_toorak\"] = new_df.apply(lambda x: haversine_distance((x[\"Lattitude\"], x[\"Longtitude\"]), toorak), axis = 1)\n",
    "new_df[\"distance_to_toorak\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Create a one hot encoding for the categorical column 'Type'\n",
    "Make sure the new columns are merged into the dataframe you are carrying through to the prediction step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3910 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      h  t  u\n",
       "1     1  0  0\n",
       "3     1  0  0\n",
       "4     1  0  0\n",
       "6     1  0  0\n",
       "7     0  0  1\n",
       "...  .. .. ..\n",
       "7985  1  0  0\n",
       "7988  1  0  0\n",
       "7995  0  1  0\n",
       "7997  0  1  0\n",
       "7999  1  0  0\n",
       "\n",
       "[3910 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_cols = pd.get_dummies(new_df['Type'])\n",
    "for col_title in type_cols:\n",
    "    new_df[col_title] = type_cols[col_title]\n",
    "type_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Calculate the correlations between all of your continuous value predictors\n",
    "Use the Pearson correlation as discussed in the lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  0.5028139970589657,\n",
       "  0.05467550446068218,\n",
       "  0.9416836881939682,\n",
       "  0.59384662591449,\n",
       "  0.4017163828132331,\n",
       "  0.5478162395802538,\n",
       "  -0.030446621758968364,\n",
       "  0.012857821622476152,\n",
       "  0.07484646284611587,\n",
       "  0.0856755549739724,\n",
       "  0.23284434150318145,\n",
       "  0.5011278514572934,\n",
       "  -0.04076215685801859,\n",
       "  -0.5351017662290412],\n",
       " [0.5028139970589657,\n",
       "  1.0,\n",
       "  0.13646832124283947,\n",
       "  0.48011522621006775,\n",
       "  0.46298456207728916,\n",
       "  0.22355172707590468,\n",
       "  0.46559774240484103,\n",
       "  -0.3305603367961711,\n",
       "  -0.2244001085292783,\n",
       "  0.18459714514251438,\n",
       "  0.06402873246014888,\n",
       "  -0.35701269892745036,\n",
       "  0.39176140501646245,\n",
       "  -0.09529455945537856,\n",
       "  -0.3727657591343631],\n",
       " [0.05467550446068218,\n",
       "  0.1364683212428395,\n",
       "  0.9999999999999998,\n",
       "  0.05931087838790853,\n",
       "  0.12204640366386925,\n",
       "  0.03469797841743664,\n",
       "  0.08935518077661954,\n",
       "  0.03556142930744642,\n",
       "  -0.44562478308501574,\n",
       "  0.4719342373418694,\n",
       "  0.014276455236059,\n",
       "  0.00806153782419569,\n",
       "  -0.04050392015644018,\n",
       "  -0.008545721818018007,\n",
       "  0.05175376880727403],\n",
       " [0.9416836881939681,\n",
       "  0.48011522621006775,\n",
       "  0.059310878387908536,\n",
       "  0.9999999999999999,\n",
       "  0.5949203420315023,\n",
       "  0.4038397574024329,\n",
       "  0.5329102296606968,\n",
       "  -0.010030835119076603,\n",
       "  0.019969776133096424,\n",
       "  0.07623564276384805,\n",
       "  0.08323717491971484,\n",
       "  0.24151497421190207,\n",
       "  0.48461199589399473,\n",
       "  -0.0373658744722959,\n",
       "  -0.5189406169695681],\n",
       " [0.59384662591449,\n",
       "  0.4629845620772892,\n",
       "  0.12204640366386926,\n",
       "  0.5949203420315023,\n",
       "  1.0,\n",
       "  0.3222656889455138,\n",
       "  0.47055375225198687,\n",
       "  0.1924697305929892,\n",
       "  -0.0686427183028252,\n",
       "  0.10931285305149321,\n",
       "  0.05948264187436437,\n",
       "  0.05166202571349794,\n",
       "  0.18177347538354904,\n",
       "  0.10814832373335405,\n",
       "  -0.28238953684255785],\n",
       " [0.401716382813233,\n",
       "  0.22355172707590468,\n",
       "  0.03469797841743664,\n",
       "  0.4038397574024329,\n",
       "  0.3222656889455138,\n",
       "  1.0,\n",
       "  0.29961335027658964,\n",
       "  0.1533126051272669,\n",
       "  -0.00783949758365398,\n",
       "  0.03291470791258251,\n",
       "  0.10068615176859202,\n",
       "  0.21475873443142068,\n",
       "  0.21417537891311034,\n",
       "  -0.006835639765164415,\n",
       "  -0.23629806786427193],\n",
       " [0.5478162395802539,\n",
       "  0.46559774240484103,\n",
       "  0.08935518077661954,\n",
       "  0.5329102296606968,\n",
       "  0.4705537522519868,\n",
       "  0.2996133502765897,\n",
       "  1.0,\n",
       "  0.02475443653556938,\n",
       "  -0.047500732739239986,\n",
       "  0.0840744555833213,\n",
       "  0.063136279163884,\n",
       "  0.07666784434695191,\n",
       "  0.30623072873744744,\n",
       "  -0.03239620968216589,\n",
       "  -0.3216142453299896],\n",
       " [-0.030446621758968367,\n",
       "  -0.3305603367961711,\n",
       "  0.03556142930744642,\n",
       "  -0.010030835119076603,\n",
       "  0.19246973059298916,\n",
       "  0.1533126051272669,\n",
       "  0.02475443653556938,\n",
       "  0.9999999999999998,\n",
       "  0.05220476602441354,\n",
       "  0.023061955029020694,\n",
       "  0.028637546636059684,\n",
       "  0.30023578750836516,\n",
       "  -0.4026697625960502,\n",
       "  0.33110492188673923,\n",
       "  0.21568884728888926],\n",
       " [0.012857821622476152,\n",
       "  -0.2244001085292783,\n",
       "  -0.4456247830850158,\n",
       "  0.019969776133096424,\n",
       "  -0.0686427183028252,\n",
       "  -0.007839497583653978,\n",
       "  -0.047500732739239986,\n",
       "  0.05220476602441355,\n",
       "  1.0,\n",
       "  -0.36633071732540984,\n",
       "  0.01073395481336509,\n",
       "  0.28168386093606645,\n",
       "  0.12125375943270181,\n",
       "  -0.02863598017786214,\n",
       "  -0.11599106319794979],\n",
       " [0.07484646284611587,\n",
       "  0.1845971451425144,\n",
       "  0.47193423734186946,\n",
       "  0.07623564276384805,\n",
       "  0.10931285305149321,\n",
       "  0.03291470791258251,\n",
       "  0.0840744555833213,\n",
       "  0.023061955029020698,\n",
       "  -0.36633071732540984,\n",
       "  0.9999999999999999,\n",
       "  0.013978769822567141,\n",
       "  -0.238933203040871,\n",
       "  -0.040387161969227536,\n",
       "  0.023602845185619073,\n",
       "  0.028532755323384847],\n",
       " [0.0856755549739724,\n",
       "  0.06402873246014888,\n",
       "  0.014276455236059003,\n",
       "  0.08323717491971484,\n",
       "  0.05948264187436437,\n",
       "  0.10068615176859201,\n",
       "  0.063136279163884,\n",
       "  0.028637546636059684,\n",
       "  0.01073395481336509,\n",
       "  0.01397876982256714,\n",
       "  0.9999999999999999,\n",
       "  0.04142008065519673,\n",
       "  0.04742187814346369,\n",
       "  -0.06725681617657286,\n",
       "  -0.005102508480926834],\n",
       " [0.23284434150318145,\n",
       "  -0.35701269892745036,\n",
       "  0.00806153782419569,\n",
       "  0.24151497421190207,\n",
       "  0.05166202571349794,\n",
       "  0.21475873443142068,\n",
       "  0.07666784434695192,\n",
       "  0.30023578750836516,\n",
       "  0.2816838609360665,\n",
       "  -0.23893320304087098,\n",
       "  0.04142008065519673,\n",
       "  0.9999999999999999,\n",
       "  0.2211043607056991,\n",
       "  -0.01419179488875281,\n",
       "  -0.2388183045120392],\n",
       " [0.5011278514572933,\n",
       "  0.39176140501646245,\n",
       "  -0.04050392015644018,\n",
       "  0.4846119958939947,\n",
       "  0.18177347538354904,\n",
       "  0.21417537891311034,\n",
       "  0.30623072873744744,\n",
       "  -0.4026697625960502,\n",
       "  0.12125375943270181,\n",
       "  -0.04038716196922754,\n",
       "  0.04742187814346369,\n",
       "  0.2211043607056991,\n",
       "  0.9999999999999999,\n",
       "  -0.48474882701989896,\n",
       "  -0.7780620398131068],\n",
       " [-0.04076215685801859,\n",
       "  -0.09529455945537856,\n",
       "  -0.008545721818018007,\n",
       "  -0.0373658744722959,\n",
       "  0.10814832373335406,\n",
       "  -0.006835639765164414,\n",
       "  -0.03239620968216589,\n",
       "  0.33110492188673923,\n",
       "  -0.02863598017786214,\n",
       "  0.023602845185619076,\n",
       "  -0.06725681617657286,\n",
       "  -0.014191794888752808,\n",
       "  -0.48474882701989896,\n",
       "  1.0,\n",
       "  -0.17228162241713466],\n",
       " [-0.535101766229041,\n",
       "  -0.3727657591343631,\n",
       "  0.05175376880727403,\n",
       "  -0.5189406169695681,\n",
       "  -0.28238953684255785,\n",
       "  -0.23629806786427196,\n",
       "  -0.3216142453299896,\n",
       "  0.21568884728888926,\n",
       "  -0.11599106319794979,\n",
       "  0.028532755323384847,\n",
       "  -0.005102508480926834,\n",
       "  -0.2388183045120392,\n",
       "  -0.7780620398131068,\n",
       "  -0.17228162241713466,\n",
       "  0.9999999999999999]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"Rooms\", \"Price\", \"Postcode\", \"Bedroom2\", \"Bathroom\", \"Car\", \"BuildingArea\", \"YearBuilt\", \"Lattitude\", \"Longtitude\", \"Landsize\", \"distance_to_toorak\", \"h\", \"t\", \"u\"]\n",
    "correlations = []\n",
    "for title1 in predictors:\n",
    "    correlations.append([new_df[title1].corr(new_df[title2]) for title2 in predictors])\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Create a linear regression model to predict home values\n",
    "Using the math in ESLII, section 3.2 equation (3.6) calculate $\\hat{\\beta}$\n",
    "\n",
    "We are going to create a linear regression model using our numeric predictor columns we selected in the last question, and the home value as are the value you are trying to predict.  You may use numpy to do matrix calculations, but you may not use a built in regression library (for example, you may not use scikt-learn). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one, build the matrix X\n",
    "new_predictors = copy.copy(predictors)\n",
    "new_predictors.remove(\"Price\")\n",
    "X = np.column_stack([np.transpose(np.array([[1 for i in range(new_df.shape[0])]])), new_df[new_predictors].to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1,  5],\n",
       "        [ 2, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step two, build the column vector y\n",
    "Y = np.transpose(np.array([new_df[\"Price\"].to_numpy()]))\n",
    "np.matrix([[1,5],[2, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step three, find beta hat per the formula (3.6)\n",
    "#beta_hat = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.transpose(), X)), X.transpose()),Y) # not working?? why?\n",
    "beta_hat = np.linalg.lstsq(X, Y, rcond = 0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Apply the linear regression model to the test data and visualize the error\n",
    "We will cover other methods of evaluating any sort of prediction later, but for this week's exercise I have partitioned the data into two files.  Load the melb_data_sold_test.csv data set and use the matrix you calculated in the last step to predict the housing prices for data in that file.  Create a visualization that shows the error in your predictions (hint:remember to do all your data pre-processing on the new file!).  For the visualization, a histogram of the absolute error vs the total housing prices is sufficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step zero, load the melb_data_sold_test.csv data for testing.  Use Imputation to fill in any missing values\n",
    "second_df = pd.read_csv(\"melb_data_sold_test.csv\")\n",
    "# mean IMPUTATION!!\n",
    "averages = [second_df[second_df[pred].notnull()][pred].mean() for pred in predictors[:-4]]\n",
    "for indx, pred in enumerate(predictors[:-4]):\n",
    "    second_df.loc[second_df[pred].isnull(), pred] = averages[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one, add the new feature for the 'distance_to_toorak' and the one hot encoding to the new data frame\n",
    "second_df[\"distance_to_toorak\"] = second_df.apply(lambda x: haversine_distance((x[\"Lattitude\"], x[\"Longtitude\"]), toorak), axis = 1)\n",
    "type_cols = pd.get_dummies(second_df['Type'])\n",
    "for col_title in type_cols:\n",
    "    second_df[col_title] = type_cols[col_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step two, build the matrix X using the new data frame\n",
    "X2 = np.column_stack([np.transpose(np.array([[1 for i in range(second_df.shape[0])]])), second_df[new_predictors].to_numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step three, multiple the new matix X by Beta hat.  This is your predicted price\n",
    "predicted_prices = np.dot(X2, beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step four, calculate the absolute value of actual price - predicted price, call this our \"absolute error\"\n",
    "# Create a histogram of the absolute error, and on the same plot create a histogram of the actual price.  \n",
    "# You should use the \"alpha\" parameter to make the graph on top slightly translucent\n",
    "error_prices = [abs(second_df.iloc[[indx]][\"Price\"].item() - price[0]) for indx, price in enumerate(predicted_prices)]\n",
    "plt.hist(error_prices, alpha=0.5, bins = 50, range = (0, 3e6))\n",
    "plt.hist(second_df[\"Price\"], alpha=0.5, bins = 50, range = (0, 3e6))\n",
    "plt.title(\"Actual Price & Error vs Observations\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.legend([\"Absolute Error of Estimate\", \"Actual Price\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
