{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C S 329E HW 4\n",
    "\n",
    "## Decision Tree Classifier\n",
    "\n",
    "## Kieran Cosgrove & Alec Biggerstaff\n",
    "\n",
    "For this weeks homework we are going to explore ideas around decision tree implementation!  \n",
    "\n",
    "We will implement some helper functions that would be necessary for a home-grown tree:\n",
    "  - calc_entropy\n",
    "  - calc_gini\n",
    "  \n",
    "and them test them out at given data splits. \n",
    "  \n",
    "And finally, to perform predictive and descriptive analytics we use the [Decision Tree Classifier](https://scikit-learn.org/stable/modules/tree.html#classification) class.\n",
    "\n",
    "  \n",
    "For this assignment, the stopping condition will be the depth of the tree. The impurity measure can be either `Entropy` or `Gini`\n",
    "\n",
    "To test our tree built from the Decision Tree Classifier class, we will revisit our Melbourne housing data (that has been cleaned and pruned) and use the files:\n",
    "\n",
    "   - `melb_tree_train.csv` for training the decision tree\n",
    "   - `melb_tree_test.csv` for testing the decision tree\n",
    "\n",
    "There are 10 features in these dataframes that we can use to describe and predict the housing \"Type\", which is 'h' house, 'u' duplex, or 't' townhome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from math import log2\n",
    "from sklearn import tree # Yes, you get to use scikit-learn this assignment, but only when I say!\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Load the Data\n",
    "Load in the melb_tree_train.csv into a dataframe, and split that dataframe into `df_X` containing the features of the data set (everything but `Type`), and `s_y`, the series containing just the label column (just `Type`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"melb_tree_train.csv\")\n",
    "df_X = df.drop(\"Type\", axis=1)\n",
    "s_y = df[\"Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Define the entropy function\n",
    "Implement a function `calc_entropy` that takes the labels series, s_y, as a parameter. Implement using the definition on p128 in the DM book and only use pandas and log2 libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(s_y):\n",
    "    totals = s_y.value_counts()\n",
    "    entropy = 0\n",
    "    for total in totals:\n",
    "        prob = total/totals.sum()\n",
    "        entropy += -prob*log2(prob)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Use the entropy function to\n",
    "  - (a) Calculate the entropy of the entire training set\n",
    "  - (b) Calculate the entropy of the three partitions formed from \n",
    "    * Landsize $\\in$ [0,200]\n",
    "    * Landsize $\\in$ (200,450]\n",
    "    * Landsize $\\in$ (450, $\\infty$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5825333114261775"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_entropy(s_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3456432116206725"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_entropy(df[df[\"Landsize\"].any() and df[\"Landsize\"] <= 200][\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4613003850147297"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_entropy(df[(df[\"Landsize\"] >= 200) & (df[\"Landsize\"] <= 450)][\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.09954792005911"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_entropy(df[(df[\"Landsize\"] >= 450)][\"Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Define the Gini Index\n",
    "Implement the function `calc_gini` that takes the labels series, s_y, as a parameter. Implement using the definition on p128 in the DM book.  Use only pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gini(s_y):\n",
    "    totals = s_y.value_counts()\n",
    "    gini = 0\n",
    "    for total in totals:\n",
    "        prob = total/totals.sum()\n",
    "        gini += prob**2\n",
    "    return 1 - gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Use the Gini Index function to\n",
    "  - (a) Calculate the Gini index of the entire training set\n",
    "  - (b) Calculate the Gini index of the three partitions formed from \n",
    "    * Landsize $\\in$ [0,200]\n",
    "    * Landsize $\\in$ (200,450]\n",
    "    * Landsize $\\in$ (450, $\\infty$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6655601280292638"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_gini(s_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5741211482422965"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_gini(df[df[\"Landsize\"].any() and df[\"Landsize\"] <= 200][\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6077339178346639"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_gini(df[(df[\"Landsize\"] >= 200) & (df[\"Landsize\"] <= 450)][\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43819341715976323"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_gini(df[(df[\"Landsize\"] >= 450)][\"Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Create a decision tree \n",
    "Using [scikit-learn](https://scikit-learn.org/stable/modules/tree.html#tree) create a multi class classifer for the data set using the Entropy impurity measure and a max depth of 3\n",
    "\n",
    "Note that scikit-learn's algorithm doesn't handle categorical data, so that needs to be preprocessed using an one hot encoding.\n",
    "\n",
    "Display the tree using `export_text` from sklearn.tree, and use that information to write some descriptive analytics on the classification of houses.  For extra fun, use the export_graphviz to draw the graph (see documentation on the [scikit-learn webpage](https://scikit-learn.org/stable/modules/tree.html#classification)).  If you are on a Windows system and get stuck reach out in the homework channel to see if anyone else could get it working for tips and tricks.  If enough people with Windows can't make the visualization, I won't count it toward the homework grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown explaination here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 Calculate the Accuracy and Display Learning Curve\n",
    "Load in the test data.\n",
    "\n",
    "Use the scikit-learn library to create decision trees with the following configurations\n",
    "\n",
    "    - Vary the max depth from 2 to 15 with the Gini Index as the impurity measure\n",
    "    - Vary the max depth from 2 to 15 with the Entropy as the impurity measure\n",
    "\n",
    "\n",
    "Evaluate the accuracy of each decision tree with both the \n",
    "  - Training set\n",
    "  - Test set\n",
    "\n",
    "Display the results graphicaly, and offer an analysis of the trend (or if no trend present, offer a hypotheisis of why).  The max depth should be on the x-axis, and the error rate should be on the y-axis (see figure 3.23 in your DM textbook for a similar style of graph that uses leaf nodes instead of depth for the x-axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
